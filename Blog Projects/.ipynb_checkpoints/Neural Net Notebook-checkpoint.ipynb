{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage import transform as tf\n",
    "from skimage import measure, feature, color, filters, draw, segmentation, morphology, exposure, transform\n",
    "from scipy import misc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.core import Dense, Activation, Merge, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random, os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import theano\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk\n",
    "%matplotlib inline\n",
    "theano.config.floatX = 'float32'\n",
    "theano.config.device = 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in test images into Python\n",
    "def random_filename_generator(path):\n",
    "    return random.choice([x for x in os.listdir(path) if os.path.isfile(os.path.join(path, x))])\n",
    "\n",
    "def generate_images(max_images=5):\n",
    "    image_list, target_list = [] , []\n",
    "    ext_list=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT']\n",
    "    for i in range(8):\n",
    "        path='/Users/thomas/Data Science Projects/Fish Identification/jpgs/train/'+ext_list[i]+'/*.jpg'\n",
    "        target=[0,0,0,0,0,0,0,0]\n",
    "        target[i]=1\n",
    "        j=0\n",
    "        file_names=[]\n",
    "        for filename in glob.glob(path):\n",
    "            file_names.append(filename)\n",
    "        while j<max_images and 0<len(file_names):\n",
    "            curr_file=random.choice(file_names)\n",
    "            file_names.remove(curr_file)\n",
    "            for filename in glob.glob(curr_file):\n",
    "                im=misc.imread(filename)\n",
    "                im=tf.resize(im,(360,640),4)\n",
    "                im=color.rgb2gray(im)\n",
    "                image_list.append(im)\n",
    "                target_list.append(target)\n",
    "                j+=1\n",
    "    return image_list,target_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers=[24, 24, 48] # Changed from 20, 40 to 24, 48\n",
    "dense_layers=[1024,512]\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Convolution2D(24,3,3, activation='relu', input_shape=(1,360,640), dim_ordering=\"th\"))\n",
    "model.add(MaxPooling2D(dim_ordering=\"th\"))\n",
    "for layer in conv_layers:\n",
    "    model.add(Convolution2D(layer, 3, 3, activation='relu', dim_ordering=\"th\"))\n",
    "    model.add(MaxPooling2D(dim_ordering=\"tf\"))\n",
    "model.add(Flatten())\n",
    "for dl in dense_layers:\n",
    "    model.add(Dense(dl, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adamax\",metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y=generate_images(45)\n",
    "X=np.reshape(X,(len(X), 1, 360, 640))\n",
    "x_train_0,x_test_0,y_train,y_test=train_test_split(X,Y,test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Making filtered images to extend training set\n",
    "\n",
    "# x_train_f_1, x_test_f_1= [], []\n",
    "# x_train_f_2, x_test_f_2= [], []\n",
    "# for image in x_train_0:\n",
    "#     x_train_f_1.append(filters.gaussian(image, sigma=.3))\n",
    "# #     x_train_f_2.append(median(image, disk(.8)))\n",
    "# for image in x_test_0:\n",
    "#     x_test_f_1.append(filters.gaussian(image, sigma=.3))\n",
    "# #     x_test_f_2.append(median(image, disk(.8)))\n",
    "# x_train_0=list(x_train_0)\n",
    "# x_test_0=list(x_test_0)\n",
    "# x_train_0.extend(x_train_f_1)\n",
    "# # x_train_0.extend(x_train_f_2)\n",
    "# x_test_0.extend(x_test_f_1)\n",
    "# # x_test_0.extend(x_test_f_2)\n",
    "\n",
    "# x_train_f_1, x_test_f_1= [], []\n",
    "# # x_train_f_2, x_test_f_2= [], []\n",
    "\n",
    "# y_train=y_train*2\n",
    "# y_test=y_test*2\n",
    "\n",
    "# x_train_0=np.reshape(x_train_0,(len(x_train_0), 1, 360, 640))\n",
    "# x_test_0=np.reshape(x_test_0,(len(x_test_0), 1, 360, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(np.array(x_train_0),y_train,batch_size=21,nb_epoch=10,shuffle=True,verbose=1,\\\n",
    "                          validation_data=(np.array(x_test_0),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X,Y=generate_images(45)\n",
    "    X=np.reshape(X,(len(X), 1, 360, 640))\n",
    "    x_train_0,x_test_0,y_train,y_test=train_test_split(X,Y,test_size=.15)\n",
    "    model.fit(np.array(x_train_0),y_train,batch_size=54,nb_epoch=3,shuffle=True,verbose=1,\\\n",
    "                          validation_data=(np.array(x_test_0),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_testing_images():\n",
    "    path='/Users/thomas/Data Science Projects/Fish Identification/jpgs/test_stg1/*.jpg'\n",
    "    testing_image_list, testing_image_name= [], []\n",
    "    for filename in glob.glob(path):\n",
    "        im=misc.imread(filename)\n",
    "        im=tf.resize(im,(360,640),4)\n",
    "        im=color.rgb2gray(im)\n",
    "        testing_image_list.append(im)\n",
    "        testing_image_name.append(filename)\n",
    "    return testing_image_list,testing_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_images,testing_files=generate_testing_images()\n",
    "testing_images=np.reshape(testing_images,(1000, 1, 360, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With 60 Images Per Class\n",
    "testing_results_proba=model.predict_proba(np.array(testing_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(testing_results_proba)\n",
    "df['image']=testing_files\n",
    "df['image']=df['image'].apply(lambda x: x.split('/')[-1])\n",
    "for i in range(8):\n",
    "    ext_list=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT']\n",
    "    df[ext_list[i]]=df[i]\n",
    "    del df[i]\n",
    "df.to_csv('/Users/thomas/Data Science Projects/Fish Identification/jpgs/test_answers.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
