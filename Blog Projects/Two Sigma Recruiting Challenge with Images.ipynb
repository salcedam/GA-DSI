{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no difference on prediction ability when using image information; will not include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier\n",
    "from sklearn import preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.layers.core import Dense, Activation, Merge, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from skimage import measure, feature, color, filters, draw, segmentation, morphology, exposure, transform\n",
    "from StringIO import StringIO\n",
    "from skimage import transform as tf\n",
    "%matplotlib inline\n",
    "\n",
    "stoppers=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_json('/Users/thomas/Data Science Projects/Two_Sigma/Files/train.json')\n",
    "train=train.loc[train.index[:100]]\n",
    "test=pd.read_json('/Users/thomas/Data Science Projects/Two_Sigma/Files/test.json')\n",
    "test=test.loc[test.index[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_index_list=[]\n",
    "image_matrix_list=[]\n",
    "image_index_list_TEST=[]\n",
    "image_matrix_list_TEST=[]\n",
    "i=0\n",
    "j=0\n",
    "for row in train.index:\n",
    "    j+=1\n",
    "    try:\n",
    "        if len(train.loc[row,'photos'])==1:\n",
    "            urls=np.random.choice(train.loc[row,'photos'],1)\n",
    "        else:\n",
    "            urls=np.random.choice(train.loc[row,'photos'],2)\n",
    "        images=[]\n",
    "        for url in urls:\n",
    "            response = requests.get(url)\n",
    "            images.append(tf.resize(np.array(Image.open(StringIO(response.content))),(125,125,3)))\n",
    "        image_matrix_list.append(images)\n",
    "        image_index_list.append([row,i])\n",
    "        i+=1\n",
    "    except:\n",
    "        print j,\n",
    "        \n",
    "print \n",
    "print '------'\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "for row in test.index:\n",
    "    j+=1\n",
    "    try:\n",
    "        urls=np.random.choice(test.loc[row,'photos'],1)\n",
    "        images=[]\n",
    "        for url in urls:\n",
    "            response = requests.get(url)\n",
    "            images.append(tf.resize(np.array(Image.open(StringIO(response.content))),(125,125,3)))\n",
    "        image_matrix_list_TEST.append(images)\n",
    "        image_index_list_TEST.append([row,i])\n",
    "        i+=1\n",
    "    except:\n",
    "        print j,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_street_address(address,street_block=True):\n",
    "    new_address=\"\"\n",
    "    temp=address.upper()\n",
    "    if \"-\" in temp:\n",
    "        temp=temp.replace('-',\" \")\n",
    "    split_address=temp.split()\n",
    "    if len(split_address)<1:\n",
    "        return \"\"\n",
    "    if len(split_address)==1:\n",
    "        return split_address[0].upper()\n",
    "    else:\n",
    "        temp=[]\n",
    "        for x in split_address:\n",
    "            if x!=\"\":\n",
    "                temp.append(x)\n",
    "        split_address=temp\n",
    "        number=\"\"\n",
    "        if len(split_address)==2:\n",
    "            pass\n",
    "        else:\n",
    "            number=split_address[0][:-2]\n",
    "            split_address=split_address[1:]\n",
    "        if len(split_address[0])>2:\n",
    "            if (split_address[0][-2:]=='ST') or (split_address[0][-2:]=='ND') or (split_address[0][-2:]=='RD'):\n",
    "                try:\n",
    "                    int(split_address[0][:-2])\n",
    "                    split_address[0]=split_address[0][:-2]\n",
    "                except:\n",
    "                    pass\n",
    "        if (split_address[-1].lower()!='w') or (split_address[-1].lower()!='e'):\n",
    "            if (split_address[-1][:2].lower()=='av') or (split_address[-1][:2].lower()=='st') or \\\n",
    "            (split_address[-1][:2].lower()=='bl') or (split_address[-1][:2].lower()=='pl'):\n",
    "                split_address[-1]=split_address[-1][:2]\n",
    "        \n",
    "        for x in split_address:\n",
    "            new_address+=x.upper()+\" \"\n",
    "        new_address=new_address[:-1]\n",
    "        new_address=new_address.replace('FIRST','1').replace('SECOND','2').replace('THIRD','3').replace('FOURTH','4')\\\n",
    "                    .replace('FIFTH','5').replace('SIXTH','6').replace('SEVENTH','7').replace('EIGTH','8')\\\n",
    "                    .replace('NINTH','9').replace('TENTH','10').replace('EAST','E').replace('WEST','W')\\\n",
    "                    .replace('E.','E').replace('W.','W')\n",
    "        if street_block:\n",
    "            if number!=\"\":\n",
    "                new_address=number+\" \"+new_address\n",
    "        return new_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['dayofyear']=train['created'].apply(lambda x: pd.to_datetime(x).dayofyear)\n",
    "test['dayofyear']=test['created'].apply(lambda x: pd.to_datetime(x).dayofyear)\n",
    "train['street_address_with_block']=train['street_address'].apply(lambda x: clean_street_address(x))\n",
    "train['street_address']=train['street_address'].apply(lambda x: clean_street_address(x,street_block=False))\n",
    "columns=[u'bathrooms', u'bedrooms',u'features',u'interest_level',u'price','latitude','longitude',\\\n",
    "      'street_address_with_block',u'street_address','dayofyear']\n",
    "train=train[columns]\n",
    "\n",
    "\n",
    "test['street_address_with_block']=test['street_address'].apply(lambda x: clean_street_address(x))\n",
    "test['street_address']=test['street_address'].apply(lambda x: clean_street_address(x,street_block=False))\n",
    "\n",
    "test['street_address_with_block']=test['street_address'].apply(lambda x: clean_street_address(x))\n",
    "test['street_address']=test['street_address'].apply(lambda x: clean_street_address(x,street_block=False))\n",
    "columns=[u'bathrooms', u'bedrooms',u'features',u'price','latitude','longitude',\\\n",
    "      'street_address_with_block',u'street_address','dayofyear']\n",
    "test=test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in train.index:\n",
    "    features=train.loc[row,'features']\n",
    "    x=\"\"\n",
    "    for feature in features:\n",
    "        x+=feature.upper().replace('-',\"\")+\" \"\n",
    "    x=x[:-1]\n",
    "    train.loc[row,'features']=x\n",
    "\n",
    "feature_dict={}\n",
    "for row in train.index:\n",
    "    for temp in train.loc[row,'features'].split():\n",
    "        if temp not in stoppers:\n",
    "            if temp in feature_dict.keys():\n",
    "                feature_dict[temp]+=1\n",
    "            else:\n",
    "                feature_dict[temp]=1\n",
    "                \n",
    "keep_list=[]\n",
    "for x in feature_dict.keys():\n",
    "    if feature_dict[x]>50:\n",
    "        keep_list.append(x)\n",
    "        \n",
    "def feature_finder(features_list,feature_to_find):\n",
    "    if feature_to_find in features_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for feature in keep_list:\n",
    "    train[str(feature)]=train['features'].apply(lambda x: feature_finder(x,feature))\n",
    "del train['features']\n",
    "\n",
    "\n",
    "# ### TESTING\n",
    "\n",
    "for row in test.index:\n",
    "    features=test.loc[row,'features']\n",
    "    x=\"\"\n",
    "    for feature in features:\n",
    "        x+=feature.upper().replace('-',\"\")+\" \"\n",
    "    x=x[:-1]\n",
    "    test.loc[row,'features']=x\n",
    "        \n",
    "for feature in keep_list:\n",
    "    test[str(feature)]=test['features'].apply(lambda x: feature_finder(x,feature))\n",
    "del test['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y=train['interest_level'].copy()\n",
    "# X=train.copy()\n",
    "# del X['interest_level']\n",
    "# X=pd.merge(X,pd.get_dummies(X['street_address_with_block']),left_index=True,right_index=True)\n",
    "# X=pd.merge(X,pd.get_dummies(X[['street_address']]),left_index=True,right_index=True)\n",
    "# del X['street_address']\n",
    "# del X['street_address_with_block']\n",
    "# # X=sparse.csr_matrix(X)\n",
    "\n",
    "# Y=[{'high':0, 'medium':1, 'low':2}[x] for x in Y]\n",
    "# x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=1)\n",
    "\n",
    "\n",
    "# X_testing_set=test.copy()\n",
    "# X_testing_set=pd.merge(X_testing_set,pd.get_dummies(X_testing_set['street_address_with_block']),left_index=True,right_index=True)\n",
    "# X_testing_set=pd.merge(X_testing_set,pd.get_dummies(X_testing_set[['street_address']]),left_index=True,right_index=True)\n",
    "# del X_testing_set['street_address']\n",
    "# del X_testing_set['street_address_with_block']\n",
    "# # X_testing_set=sparse.csr_matrix(X_testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data_frame=pd.DataFrame(image_index_list,columns=['df_index','matrix_index'])\n",
    "train=pd.merge(train,image_data_frame,left_index=True,right_on='df_index',how='left')\n",
    "\n",
    "image_data_frame_TEST=pd.DataFrame(image_index_list_TEST,columns=['df_index','matrix_index'])\n",
    "test=pd.merge(test,image_data_frame_TEST,left_index=True,right_on='df_index',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=train['interest_level'].copy()\n",
    "X=train.copy()\n",
    "del X['interest_level']\n",
    "del X['street_address']\n",
    "del X['street_address_with_block']\n",
    "X=X.reset_index(drop=True)\n",
    "# X=sparse.csr_matrix(X)\n",
    "\n",
    "Y=[{'high':0, 'medium':1, 'low':2}[x] for x in Y]\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=1)\n",
    "\n",
    "\n",
    "X_testing_set=test.copy()\n",
    "del X_testing_set['street_address']\n",
    "del X_testing_set['street_address_with_block']\n",
    "# X_testing_set=sparse.csr_matrix(X_testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_image=np.array([[Y[z],z] for z in [x for x,y in zip(x_train.index,x_train['matrix_index']) if\\\n",
    "                                             pd.notnull(y)]]).T\n",
    "y_test_image=np.array([[Y[z],z] for z in [x for x,y in zip(x_test.index,x_test['matrix_index']) if\\\n",
    "                                            pd.notnull(y)]]).T\n",
    "testing_set_image_index=np.array([[Y[z],z] for z in [x for x,y in \\\n",
    "                        zip(X_testing_set.index,X_testing_set['matrix_index']) if pd.notnull(y)]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_image_key=x_train.loc[:,x_train.columns[-2:]]\n",
    "x_test_image_key=x_test.loc[:,x_test.columns[-2:]]\n",
    "x_train=x_train.loc[:,x_train.columns[:-2]]\n",
    "x_test=x_test.loc[:,x_test.columns[:-2]]\n",
    "\n",
    "x_train_images_list=[np.array(image_matrix_list[index][0]).flatten() for \\\n",
    "                     index in [int(x) for x in x_train_image_key['matrix_index'].values if pd.notnull(x)]]\n",
    "x_test_images_list=[np.array(image_matrix_list[index][0]).flatten() for \\\n",
    "                    index in [int(x) for x in x_test_image_key['matrix_index'].values if pd.notnull(x)]]\n",
    "\n",
    "#----------------------------------------\n",
    "X_testing_set_image_key=X_testing_set.loc[:,X_testing_set.columns[-2:]]\n",
    "X_testing_set=X_testing_set.loc[:,X_testing_set.columns[:-2]]\n",
    "X_testing_set_images_list=[np.array(image_matrix_list_TEST[index][0]).flatten() for \\\n",
    "                     index in [int(x) for x in X_testing_set_image_key['matrix_index'].values if pd.notnull(x)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'multi:softprob' \n",
    "param['eta'] = 0.1 # 0.05\n",
    "param['max_depth'] = 4 # 3\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "param['eval_metric'] = \"mlogloss\"\n",
    "param['min_child_weight'] = 15       # 2\n",
    "param['subsample'] = 0.5            # .5  \n",
    "param['colsample_bytree'] = 1.      # 1.  \n",
    "\n",
    "plst = list(param.items())\n",
    "\n",
    "xgtrain = xgb.DMatrix(np.array(x_train_images_list), label=y_train_image[0])\n",
    "xgtest = xgb.DMatrix(np.array(x_test_images_list), label=y_test_image[0])\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "\n",
    "model=xgb.train(plst, xgtrain, 4000, watchlist, early_stopping_rounds=10)\n",
    "preds = model.predict(xgb.DMatrix(X_testing_set_images_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-mlogloss:0.739025\ttest-mlogloss:0.797758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(model.predict(xgtrain))\n",
    "temp['index_lookup']=y_train_image[1]\n",
    "x_train_final=pd.merge(x_train,temp,left_index=True,right_on='index_lookup', how='left')\n",
    "del x_train_final['index_lookup']\n",
    "x_train_final=sparse.csr_matrix(x_train_final)\n",
    "#----\n",
    "temp=pd.DataFrame(model.predict(xgtest))\n",
    "temp['index_lookup']=y_test_image[1]\n",
    "x_test_final=pd.merge(x_test,temp,left_index=True,right_on='index_lookup', how='left')\n",
    "del x_test_final['index_lookup']\n",
    "x_test_final=sparse.csr_matrix(x_test_final)\n",
    "#----\n",
    "temp=pd.DataFrame(preds)\n",
    "temp['index_lookup']=testing_set_image_index[1]\n",
    "X_testing_set_final=pd.merge(X_testing_set,temp,left_index=True,right_on='index_lookup', how='left')\n",
    "del X_testing_set_final['index_lookup']\n",
    "X_testing_set_final=sparse.csr_matrix(X_testing_set_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'multi:softprob' \n",
    "param['eta'] = 0.05 # 0.05\n",
    "param['max_depth'] = 6 # 6\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "param['eval_metric'] = \"mlogloss\"\n",
    "param['min_child_weight'] = 2       # 2\n",
    "param['subsample'] = 0.5            # .5  \n",
    "param['colsample_bytree'] = .75      # 1.  \n",
    "\n",
    "plst = list(param.items())\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "xgtest = xgb.DMatrix(x_test, label=y_test)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "\n",
    "model=xgb.train(plst, xgtrain, 4000, watchlist, early_stopping_rounds=25)\n",
    "# preds = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-mlogloss:0.436267\ttest-mlogloss:0.615509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
