{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you so much for taking the time to read through my Capstone project's notebook. The capstone project is the crowning achievement of the GA DSI course, and serves to exemplify the variety of skills I have learned throughout the past few months. As such, I have taken time to choose a topic that requires both a variety of skills and proves to be a creative idea. Thus, I have chosen my Capstone project to be a personality based subreddit recommendation engine. \n",
    "\n",
    "What prompted this capstone idea was the grave of my previous capstone idea, which was determining what news articles would qualify as being significant to the stock market. I found that the approach I wanted to take for that capstone idea would be unsuccessful due to the nature of my methodology. I was going to analyze thousands of articles posted to reddit.com and their associated comments relative to stock market movement. I found, though, through trial, error, and classroom discussions that there was an abundance of issues that would be unresolvable due to the inherent randomness and complexity of the markets. \n",
    "\n",
    "With the frustration of no longer having a viable project, I looked to scavenge what I could from my work. Perhaps the most important code of my work was the subreddit API scraping and cleaning code. The scraping code was simple to write, but the cleaning code in my mind would prove to be an invaluable resource should I choose to reuse my code. Thus, I started thinking of ideas that would allow me to reuse this code, as there was so much information available from the data.\n",
    "\n",
    "The idea I settled on was to model the personalities of subreddits and associated users to generate an ensembled search engine for subreddit recommendation. The idea was to scrape the comments and links over tens of thousands of posts spanning hundreds of subreddits to identify unique personalities amongst the subreddits and users. From this scraped and inferred information, I would be able to identify key commonalities in user preferences and subreddit personalities, which would allow me to create a euclidian based coordinate-system to identify the most similar subreddits and users. I would ensemble the two by:\n",
    "\n",
    "* Requesting the subscribed subreddits of a participant\n",
    "* Identifying the users with similar preferences from my user-subreddit list\n",
    "* Generating a list of subreddits found in other users' data, but not in the participant's data\n",
    "* Determining which of the subreddits within the generated list was most similar to the participant's list\n",
    "* Returning that most similar subreddit\n",
    "\n",
    "From this system, I would be able to tell a participant which subreddit they would really enjoy.\n",
    "\n",
    "However, I encountered a major problem whilst trying to complete these tasks: the usernames returned from the API were hashed user id's, not usernames. So, the user id's represented in my data were a one-way key to the real usernames, which I had no way of getting, unless I chose to scrape the posts manually. I decided not to do this due to reddit's extremely strict webscraping and API rules. If I were to ping reddit more than 30 times a minute or if I didn't supply the proper credentials in my requests, I would be perma-banned from the site. Due to this risk, I chose to proceed without the user data, and to create a model consisting solely of subreddit personality information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
