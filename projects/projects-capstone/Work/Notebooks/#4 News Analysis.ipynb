{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from nltk.stem import SnowballStemmer,PorterStemmer\n",
    "from stemming import lovins,porter2,paicehusk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stop_words\n",
    "import pprint\n",
    "import re\n",
    "import time\n",
    "import spacy\n",
    "import datetime\n",
    "import requests\n",
    "import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting JSON Loading\n",
      "Loading JSON at Time: 1.58150990804e-06 Minutes\n",
      "Loading JSON at Time: 0.955058598518 Minutes\n",
      "Loading JSON at Time: 2.19378606478 Minutes\n",
      "Loading JSON at Time: 3.52724283139 Minutes\n",
      "Loading JSON at Time: 3.82851681709 Minutes\n",
      "Loading JSON at Time: 4.97993968328 Minutes\n",
      "Loading JSON at Time: 6.52209508419 Minutes\n",
      "Finished JSON Loading\n",
      "Took: 7.38683884939 Minutes\n",
      "\n",
      "Starting DF reformatting\n",
      "Finished DF reformatting\n",
      "Took: 0.862464189529 Seconds\n"
     ]
    }
   ],
   "source": [
    "### THIS CODE LOADS THE JSONS OF THE VECTORIZED REDDIT COMMENTS, AND GETS IT TO ITS PRIOR USABLE STATE\n",
    "total_time=time.time()\n",
    "print \"Starting Reddit DF Loading\"\n",
    "start_time=time.time()\n",
    "news=pd.read_json('../r_news.json')\n",
    "worldnews=pd.read_json('../r_worldnews.json')\n",
    "tech=pd.read_json('../r_technology.json')\n",
    "stock=pd.read_json('../r_StockMarket.json')\n",
    "politics=pd.read_json('../r_politics.json')\n",
    "inthenews=pd.read_json('../r_inthenews.json')\n",
    "futurology=pd.read_json('../r_Futurology.json')\n",
    "dfs={'news':news,'worldnews':worldnews,'tech':tech,'stock':stock,'politics':politics,\\\n",
    "     'inthenews':inthenews,'futurology':futurology}\n",
    "for name in dfs.keys():\n",
    "    df=dfs[name]\n",
    "    for i in range(len(df.columns)):\n",
    "        all_words=pprint.pformat(df.iloc[4,i])\n",
    "        all_words=all_words.replace(\"\\n\",\" \").replace(\"\\\\n\",\" \").replace(\"{u'comment': \",\"\")\\\n",
    "                .replace(\",\",\"\").replace(\"ucomment: \",\"\")\n",
    "        all_words=re.sub(r\"[\\[\\]]+\",\" \",all_words)\n",
    "        all_words=re.sub(r\"\\Wu\\'id\\': \\w\\'\\w{7}\\'\",\"\",all_words).replace(\"{\",\"\").replace(\"}\",\"\").replace(\"      \",\" \")\\\n",
    "                    .replace(\"\\\\\\'\",\"\\'\").replace(\"' u\\'\",\" \").replace(\" u\\'\",\"\")\n",
    "        all_words=re.sub(r\"\\\\u20..\",\"\",all_words).replace(\"\\'\",\"\").replace(' u\"',\"\")\n",
    "        all_words=re.sub(r\"[A-Za-z]*[0-9]+[A-Za-z]*\",\"\",all_words).replace(\"*\",\"\")\n",
    "        df.iloc[4,i]=all_words\n",
    "    dfs[name]=df\n",
    "print \"Finished Reddit DF Loading\"\n",
    "print \"Took %s Minutes\"%((time.time()-start_time)/60.)\n",
    "print \n",
    "\n",
    "jsons=[]\n",
    "json_dfs=[]\n",
    "print \"Starting Vectorized Words Loading\"\n",
    "start_time=time.time()\n",
    "for link in ['../vectorized_r_news.json','../vectorized_r_worldnews.json','../vectorized_r_technology.json',\\\n",
    "            '../vectorized_r_StockMarket.json','../vectorized_r_politics.json','../vectorized_r_inthenews.json',\\\n",
    "            '../vectorized_r_Futurology.json']:\n",
    "    jsons.append(pd.read_json(link))\n",
    "\n",
    "start_time=time.time()\n",
    "for i in range(len(jsons)):\n",
    "    temp_df=jsons[i]\n",
    "    temp_df=temp_df.T.sort_values(\"Mean\",ascending=False)\n",
    "    del temp_df[\"Mean\"]\n",
    "    new_cols=[]\n",
    "    for col in temp_df.columns:\n",
    "        new_cols.append(int(col))\n",
    "    temp_df.columns=new_cols\n",
    "    temp_df[\"Mean\"]=temp_df.T.mean()\n",
    "    temp_df=temp_df.sort_values(\"Mean\",ascending=False).T.sort_index()\n",
    "    json_dfs.append(temp_df)\n",
    "print \"Finished Vectorized Words Loading\"\n",
    "print \"Took: %s Minutes\" %((time.time()-start_time)/60.)\n",
    "print\n",
    "\n",
    "###---\n",
    "\n",
    "start_time=time.time()\n",
    "print \"Starting Fed, Keywords, and Pos/Neg\"\n",
    "fed=pd.read_json('../fed_info.json')\n",
    "del fed['f2015043']\n",
    "del fed['f2015042']\n",
    "cols=[]\n",
    "for col in fed.columns:\n",
    "    if col[0]!='f':\n",
    "        name=col[:4]+'-'+col[4:6]+'-'+col[6:]\n",
    "        cols.append(name)\n",
    "    else: print col\n",
    "cols=pd.to_datetime(cols)\n",
    "fed.columns=cols\n",
    "# We eliminated columns before the 119th because we want to focus in on a 1 year period. We state the end of the \n",
    "# period is the last date in our data set\n",
    "fed=fed.iloc[:,119:]\n",
    "keywords=pd.read_json('../key_terms.json').reset_index()\n",
    "keywords['index']=keywords['index'].astype(int)\n",
    "keywords=keywords.sort_values('index')\n",
    "keywords.index=keywords['index']\n",
    "del keywords['index']\n",
    "keywords.columns=['Type','Value']\n",
    "keywords[\"Value\"]=keywords[\"Value\"].apply(lambda x:x.lower())\n",
    "\n",
    "posneg=pd.read_csv('../subjectivity of words.txt')\n",
    "word_list=['type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative'.split(\" \")]\n",
    "posneg.columns=['col']\n",
    "for row in posneg['col']:\n",
    "    word_list.append(row.split(\" \"))\n",
    "posneg=[]\n",
    "for x in word_list:\n",
    "    posneg.append([])\n",
    "    for y in x:\n",
    "        posneg[-1].append(y.split(\"=\")[-1])\n",
    "posneg=pd.DataFrame(posneg)\n",
    "posneg.columns=['type','len','word','pos','stemmed','priorpolarity','N/A']\n",
    "print \"Finished Fed, Keywords, Pos/Neg\"\n",
    "print \"Took: %s Minutes\" %((time.time()-start_time())/60.)\n",
    "print \"\\n \\n\"\n",
    "print \"Total time: %s Minutes\"%((time.time()-total_time)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Reddit DF Loading\n",
      "Finished Reddit DF Loading\n",
      "Took: 86.6783220768\n"
     ]
    }
   ],
   "source": [
    "print \"Starting Reddit DF Loading\"\n",
    "start_time=time.time()\n",
    "news=pd.read_json('../r_news.json')\n",
    "worldnews=pd.read_json('../r_worldnews.json')\n",
    "tech=pd.read_json('../r_technology.json')\n",
    "stock=pd.read_json('../r_StockMarket.json')\n",
    "politics=pd.read_json('../r_politics.json')\n",
    "inthenews=pd.read_json('../r_inthenews.json')\n",
    "futurology=pd.read_json('../r_Futurology.json')\n",
    "dfs={'news':news,'worldnews':worldnews,'tech':tech,'stock':stock,'politics':politics,\\\n",
    "     'inthenews':inthenews,'futurology':futurology}\n",
    "for name in dfs.keys():\n",
    "    df=dfs[name]\n",
    "    for i in range(len(df.columns)):\n",
    "        all_words=pprint.pformat(df.iloc[4,i])\n",
    "        all_words=all_words.replace(\"\\n\",\" \").replace(\"\\\\n\",\" \").replace(\"{u'comment': \",\"\")\\\n",
    "                .replace(\",\",\"\").replace(\"ucomment: \",\"\")\n",
    "        all_words=re.sub(r\"[\\[\\]]+\",\" \",all_words)\n",
    "        all_words=re.sub(r\"\\Wu\\'id\\': \\w\\'\\w{7}\\'\",\"\",all_words).replace(\"{\",\"\").replace(\"}\",\"\").replace(\"      \",\" \")\\\n",
    "                    .replace(\"\\\\\\'\",\"\\'\").replace(\"' u\\'\",\" \").replace(\" u\\'\",\"\")\n",
    "        all_words=re.sub(r\"\\\\u20..\",\"\",all_words).replace(\"\\'\",\"\").replace(' u\"',\"\")\n",
    "        all_words=re.sub(r\"[A-Za-z]*[0-9]+[A-Za-z]*\",\"\",all_words).replace(\"*\",\"\")\n",
    "        df.iloc[4,i]=all_words\n",
    "    dfs[name]=df\n",
    "print \"Finished Reddit DF Loading\"\n",
    "print \"Took:\",time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of all the words, and link the word to a keyword identity and strength. \n",
    "It might be smart to take a series of documents and find out how often each of the keysords appears. From this, one could deduce an implied strength by their relevance in the articles. Financial articles would be the best choice for this. (Maybe scrape Yahoo finance?)\n",
    "\n",
    "Categorize the post to the identities and give them a strength.\n",
    "    \n",
    "* There would be a column for each type of keyword. The value of the column would be the sum of the keywords with that category. The algorithms would weight each of those values linearly, so scale them appropriately before. This would be done just after the vectorization process.\n",
    "    \n",
    "The next step is to introduce the sentiment implied by the comments and the direction of this sentiment. It might be smart to use only the top posts, and none of their child comments (they can get pretty stupid.) However, there are some subreddits with sane commentors; we wouldn't necessarily need to filter these (especially as they will probably have fewer comments).\n",
    "\n",
    "After the vectorized sentiment has been calculated, we will have keywords to identify them with. If the keywords in the comments match what is in the title, then it is safe to assume an implied investor sentiment; this will be a column. (Here, it might be smart to create derivative columns consisting of the implied sentiment column and the identity columns).\n",
    "\n",
    "From here, we can begin to look at classifications, regressions, and clustering.\n",
    "\n",
    "We want to predict $\\Delta$Price, and reset the price on the day after we think it is going to be realized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Go through all of the fed articles and see:\n",
    "\n",
    "    1) How many times each type of keyword occurs \n",
    "    2) How many times each keyword appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_dict_pos={}\n",
    "for word in keywords['Type']:\n",
    "    type_dict_pos[word]=0\n",
    "type_dict_neg=type_dict_pos.copy()\n",
    "type_dict_gen=type_dict_pos.copy()\n",
    "word_dict_pos={}\n",
    "for word in keywords['Value']:\n",
    "    word_dict_pos[word]=0\n",
    "word_dict_neg=word_dict_pos.copy()\n",
    "word_dict_gen=word_dict_pos.copy()\n",
    "\n",
    "\n",
    "\n",
    "for col in fed.columns:\n",
    "    title=fed.loc[0,col]\n",
    "    pos_count=0\n",
    "    neg_count=0\n",
    "    for word in posneg['word']:\n",
    "        if word in title:\n",
    "            sentiment=posneg[posneg['word']==word]['priorpolarity'].values[0]\n",
    "            if sentiment=='negative':\n",
    "                neg_count+=1\n",
    "            elif sentiment=='positive':\n",
    "                pos_count+=1\n",
    "    article=\"\"\n",
    "    for x in fed.loc[2,col]:\n",
    "        article+=x.lower()+' '\n",
    "    if pos_count>neg_count:\n",
    "        for word in keywords['Value']:\n",
    "            if word in article:\n",
    "                word_dict_pos[word]+=1\n",
    "                type_dict_pos[keywords[keywords['Value']==word]['Type'].values[0]]+=1\n",
    "    elif pos_count<neg_count:\n",
    "        for word in keywords['Value']:\n",
    "            if word in article:\n",
    "                word_dict_neg[word]+=1\n",
    "                type_dict_neg[keywords[keywords['Value']==word]['Type'].values[0]]+=1\n",
    "    else:\n",
    "        for word in keywords['Value']:\n",
    "            if word in article:\n",
    "                word_dict_gen[word]+=1\n",
    "                type_dict_gen[keywords[keywords['Value']==word]['Type'].values[0]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_results=pd.DataFrame([word_dict_neg,word_dict_pos,word_dict_gen]).T\n",
    "word_results.columns=['Negative','Positive',\"General\"]\n",
    "word_results[\"Occurences\"]=word_results[\"Positive\"]+word_results[\"Negative\"]+word_results[\"General\"]\n",
    "word_results[\"Rating\"]=(word_results[\"Positive\"]-word_results['Negative'])/word_results[\"Occurences\"]\n",
    "word_results[word_results['Occurences']>3].sort_values(\"Rating\")[[\"Occurences\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurences</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iowa</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>georgia</th>\n",
       "      <td>40</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indiana</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maryland</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>massachusetts</th>\n",
       "      <td>12</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minnesota</th>\n",
       "      <td>16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columbus</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>69</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>518</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ohio</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missouri</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arizona</th>\n",
       "      <td>11</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alabama</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oklahoma</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kansas</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginia</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san francisco</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trading</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kansas city</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicago</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accepted</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>120</td>\n",
       "      <td>-0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>118</td>\n",
       "      <td>-0.347458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankrupt</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankruptcy</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equity</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rice</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implementation</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pennsylvania</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owed</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inflation</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorado</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columbia</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>federal register</th>\n",
       "      <td>48</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unity</th>\n",
       "      <td>19</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>18</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquidity</th>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texas</th>\n",
       "      <td>114</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authority</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goldman sachs</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>federal reserve system</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north carolina</th>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loans</th>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connecticut</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utah</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louisiana</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Occurences    Rating\n",
       "iowa                             8 -1.000000\n",
       "georgia                         40 -1.000000\n",
       "indiana                         10 -1.000000\n",
       "maryland                         4 -1.000000\n",
       "massachusetts                   12 -1.000000\n",
       "minnesota                       16 -1.000000\n",
       "columbus                         4 -1.000000\n",
       "florida                         69 -1.000000\n",
       "california                     518 -1.000000\n",
       "ohio                            14 -1.000000\n",
       "missouri                        24 -1.000000\n",
       "arizona                         11 -1.000000\n",
       "alabama                         10 -1.000000\n",
       "stock                            4 -1.000000\n",
       "oklahoma                        10 -1.000000\n",
       "kansas                          35 -0.800000\n",
       "virginia                        40 -0.800000\n",
       "san francisco                    4 -0.750000\n",
       "trading                          8 -0.750000\n",
       "city                             5 -0.600000\n",
       "exchange                         7 -0.571429\n",
       "kansas city                      4 -0.500000\n",
       "finance                          6 -0.500000\n",
       "government                      14 -0.428571\n",
       "chicago                          5 -0.400000\n",
       "accepted                         5 -0.400000\n",
       "department                       5 -0.400000\n",
       "million                          8 -0.375000\n",
       "nation                         120 -0.366667\n",
       "media                          118 -0.347458\n",
       "...                            ...       ...\n",
       "bankrupt                         4  0.000000\n",
       "bankruptcy                       4  0.000000\n",
       "equity                           8  0.000000\n",
       "rice                            11  0.000000\n",
       "rates                            5  0.000000\n",
       "implementation                  13  0.000000\n",
       "pennsylvania                    16  0.000000\n",
       "price                           11  0.000000\n",
       "paid                             6  0.000000\n",
       "owed                             7  0.000000\n",
       "inflation                       14  0.000000\n",
       "colorado                        26  0.000000\n",
       "debt                            12  0.000000\n",
       "columbia                         6  0.000000\n",
       "federal register                48  0.083333\n",
       "unity                           19  0.105263\n",
       "business                        18  0.111111\n",
       "liquidity                        6  0.166667\n",
       "texas                          114  0.333333\n",
       "economy                          5  0.400000\n",
       "authority                        6  0.500000\n",
       "loan                             8  0.500000\n",
       "gold                             4  0.500000\n",
       "goldman sachs                    4  0.500000\n",
       "federal reserve system           6  0.500000\n",
       "north carolina                  40  0.500000\n",
       "loans                            5  0.600000\n",
       "connecticut                      6  1.000000\n",
       "utah                             5  1.000000\n",
       "louisiana                        5  1.000000\n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_results[word_results['Occurences']>3].sort_values(\"Rating\")[[\"Occurences\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_dict_pos={}\n",
    "for word in keywords['Type']:\n",
    "    type_dict_pos[word]=0\n",
    "type_dict_neg=type_dict_pos.copy()\n",
    "type_dict_gen=type_dict_pos.copy()\n",
    "word_dict_pos={}\n",
    "for word in keywords['Value']:\n",
    "    word_dict_pos[word]=0\n",
    "word_dict_neg=word_dict_pos.copy()\n",
    "word_dict_gen=word_dict_pos.copy()\n",
    "\n",
    "\n",
    "article_row=4\n",
    "for name in dfs.keys():\n",
    "    df=dfs[name]\n",
    "    for col in df.columns:\n",
    "        title=df.loc[0,col]\n",
    "        pos_count=0\n",
    "        neg_count=0\n",
    "        for word in posneg['word']:\n",
    "            if word in title:\n",
    "                sentiment=posneg[posneg['word']==word]['priorpolarity'].values[0]\n",
    "                if sentiment=='negative':\n",
    "                    neg_count+=1\n",
    "                elif sentiment=='positive':\n",
    "                    pos_count+=1\n",
    "    # Use for fed\n",
    "    #     article=\"\"\n",
    "    #     for x in df.loc[article_row,col]:\n",
    "    #         article+=x.lower()+' '\n",
    "        article=df.loc[article_row,col].lower()\n",
    "        if pos_count>neg_count:\n",
    "            for word in keywords['Value']:\n",
    "                if word in article:\n",
    "                    word_dict_pos[word]+=1\n",
    "                    type_dict_pos[keywords[keywords['Value']==word]['Type'].values[0]]+=1\n",
    "        elif pos_count<neg_count:\n",
    "            for word in keywords['Value']:\n",
    "                if word in article:\n",
    "                    word_dict_neg[word]+=1\n",
    "                    type_dict_neg[keywords[keywords['Value']==word]['Type'].values[0]]+=1\n",
    "        else:\n",
    "            for word in keywords['Value']:\n",
    "                if word in article:\n",
    "                    word_dict_gen[word]+=1\n",
    "                    type_dict_gen[keywords[keywords['Value']==word]['Type'].values[0]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurences</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>federal election commission</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halliburton</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tucson</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>limited government</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmentalism</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kroger</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open primary</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closed primary</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceived</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berkeley</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louisiana</th>\n",
       "      <td>510</td>\n",
       "      <td>-0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san bernardino</th>\n",
       "      <td>58</td>\n",
       "      <td>-0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norman</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tyler</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individualism</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomet</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national convention</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiscal year</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civil service</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yielded</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raleigh</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roe v. wade</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craigslist</th>\n",
       "      <td>46</td>\n",
       "      <td>-0.586957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbr</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public policy</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.574074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>federalism</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gag order</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charlotte</th>\n",
       "      <td>37</td>\n",
       "      <td>-0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delaware</th>\n",
       "      <td>67</td>\n",
       "      <td>-0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burger king</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eureka</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waco</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salt lake city</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>businessmen</th>\n",
       "      <td>63</td>\n",
       "      <td>-0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker of the house</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xerox</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san jose</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anarchism</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot topic</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bundling</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulsa</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>richmond</th>\n",
       "      <td>36</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antec</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plurality</th>\n",
       "      <td>45</td>\n",
       "      <td>-0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minneapolis</th>\n",
       "      <td>46</td>\n",
       "      <td>-0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converse</th>\n",
       "      <td>93</td>\n",
       "      <td>-0.139785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollster</th>\n",
       "      <td>36</td>\n",
       "      <td>-0.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cambridge</th>\n",
       "      <td>37</td>\n",
       "      <td>-0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesa</th>\n",
       "      <td>38</td>\n",
       "      <td>-0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation-state</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orlando</th>\n",
       "      <td>74</td>\n",
       "      <td>-0.121622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lockheed martin</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guam</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edison</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiscal policy</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welfare state</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fairness doctrine</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manchester</th>\n",
       "      <td>21</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boulder</th>\n",
       "      <td>29</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Occurences    Rating\n",
       "federal election commission          18 -0.888889\n",
       "halliburton                          31 -0.806452\n",
       "tucson                               21 -0.761905\n",
       "limited government                   20 -0.750000\n",
       "environmentalism                     24 -0.708333\n",
       "kroger                               25 -0.680000\n",
       "open primary                         24 -0.666667\n",
       "closed primary                       26 -0.653846\n",
       "deceived                             25 -0.640000\n",
       "berkeley                             30 -0.633333\n",
       "louisiana                           510 -0.627451\n",
       "san bernardino                       58 -0.620690\n",
       "norman                               18 -0.611111\n",
       "tyler                                18 -0.611111\n",
       "individualism                        18 -0.611111\n",
       "biomet                               23 -0.608696\n",
       "national convention                  35 -0.600000\n",
       "fiscal year                          42 -0.595238\n",
       "civil service                        32 -0.593750\n",
       "yielded                              22 -0.590909\n",
       "raleigh                              17 -0.588235\n",
       "roe v. wade                          17 -0.588235\n",
       "craigslist                           46 -0.586957\n",
       "kbr                                  19 -0.578947\n",
       "public policy                        54 -0.574074\n",
       "federalism                           21 -0.571429\n",
       "gag order                            42 -0.571429\n",
       "charlotte                            37 -0.567568\n",
       "delaware                             67 -0.567164\n",
       "burger king                          25 -0.560000\n",
       "...                                 ...       ...\n",
       "eureka                               25 -0.200000\n",
       "waco                                 20 -0.200000\n",
       "salt lake city                       21 -0.190476\n",
       "businessmen                          63 -0.190476\n",
       "speaker of the house                 21 -0.190476\n",
       "xerox                                16 -0.187500\n",
       "san jose                             22 -0.181818\n",
       "bilateral                            17 -0.176471\n",
       "anarchism                            17 -0.176471\n",
       "hot topic                            29 -0.172414\n",
       "bundling                             35 -0.171429\n",
       "tulsa                                18 -0.166667\n",
       "richmond                             36 -0.166667\n",
       "antec                                31 -0.161290\n",
       "plurality                            45 -0.155556\n",
       "minneapolis                          46 -0.152174\n",
       "converse                             93 -0.139785\n",
       "pollster                             36 -0.138889\n",
       "cambridge                            37 -0.135135\n",
       "mesa                                 38 -0.131579\n",
       "nation-state                         16 -0.125000\n",
       "orlando                              74 -0.121622\n",
       "lockheed martin                      27 -0.111111\n",
       "guam                                 18 -0.111111\n",
       "edison                               42 -0.071429\n",
       "fiscal policy                        18 -0.055556\n",
       "welfare state                        48 -0.041667\n",
       "fairness doctrine                    20  0.000000\n",
       "manchester                           21  0.047619\n",
       "boulder                              29  0.172414\n",
       "\n",
       "[533 rows x 2 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_results=pd.DataFrame([word_dict_neg,word_dict_pos,word_dict_gen]).T\n",
    "word_results.columns=['Negative','Positive',\"General\"]\n",
    "word_results[\"Occurences\"]=word_results[\"Positive\"]+word_results[\"Negative\"]+word_results[\"General\"]\n",
    "word_results[\"Rating\"]=(word_results[\"Positive\"]-word_results['Negative'])/word_results[\"Occurences\"]\n",
    "word_results[word_results['Occurences']>15].sort_values(\"Rating\")[[\"Occurences\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
